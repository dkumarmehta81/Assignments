{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.backend import function\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.layers import Input, Multiply\nfrom tensorflow.keras.applications import InceptionV3,MobileNet\nfrom sklearn.utils import resample\nimport keras as K","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:04:25.011236Z","iopub.execute_input":"2023-10-12T14:04:25.011616Z","iopub.status.idle":"2023-10-12T14:04:32.997060Z","shell.execute_reply.started":"2023-10-12T14:04:25.011584Z","shell.execute_reply":"2023-10-12T14:04:32.996105Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set a random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:04:32.998961Z","iopub.execute_input":"2023-10-12T14:04:32.999818Z","iopub.status.idle":"2023-10-12T14:04:33.004587Z","shell.execute_reply.started":"2023-10-12T14:04:32.999784Z","shell.execute_reply":"2023-10-12T14:04:33.003608Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Local Attention Module Declaration","metadata":{}},{"cell_type":"code","source":"\ndef attention_module(input_tensor, kernel_size=3):\n    # Local attention module implementation\n    x = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(input_tensor)\n    x = Multiply()([input_tensor, x])\n\n    # Apply local attention by convolving with a kernel centered on each pixel\n    local_attention = Conv2D(filters=1, kernel_size=kernel_size, padding='same', activation='sigmoid')(x)\n    x = Multiply()([x, local_attention])\n    \n    return x\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:04:33.005844Z","iopub.execute_input":"2023-10-12T14:04:33.006173Z","iopub.status.idle":"2023-10-12T14:04:33.015668Z","shell.execute_reply.started":"2023-10-12T14:04:33.006143Z","shell.execute_reply":"2023-10-12T14:04:33.014831Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def spatial_attention(input_feature):\n\tkernel_size = 7\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature.shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature.shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool.shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool.shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat.shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tactivation='sigmoid',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\t\n\tassert cbam_feature.shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])\n\t\t","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:04:33.017897Z","iopub.execute_input":"2023-10-12T14:04:33.018717Z","iopub.status.idle":"2023-10-12T14:04:33.026728Z","shell.execute_reply.started":"2023-10-12T14:04:33.018688Z","shell.execute_reply":"2023-10-12T14:04:33.025826Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Local Mobile Net Model Fine Tuning","metadata":{}},{"cell_type":"code","source":"def create_Local_attention_augmented_mobilenet(input_shape, num_classes,attention=True):\n    # Load MobileNet base model without top layer\n    base_model = tf.keras.applications.MobileNet(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = False\n\n    # Attention augmented MobileNet architecture\n    input_tensor = Input(shape=input_shape)\n    x = base_model(input_tensor)\n    if(attention):\n        x = Concatenate(axis=-1)([spatial_attention(x),x])\n        x = tf.keras.layers.MaxPooling2D()(x)\n        x = Concatenate(axis=-1)([spatial_attention(x),x])\n        x = tf.keras.layers.MaxPooling2D()(x)\n\n    # Add classification layers\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    output_tensor = Dense(num_classes, activation='sigmoid')(x)\n\n    # Create the model\n    model = Model(inputs=input_tensor, outputs=output_tensor)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:44:52.703694Z","iopub.execute_input":"2023-10-12T14:44:52.704153Z","iopub.status.idle":"2023-10-12T14:44:52.711869Z","shell.execute_reply.started":"2023-10-12T14:44:52.704113Z","shell.execute_reply":"2023-10-12T14:44:52.710606Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Local InceptionV3 Model Fine Tuning","metadata":{}},{"cell_type":"code","source":"def create_Local_Inceptionv3_model(input_shape, num_classes,attention=True):\n    \n    # Load Inception-v3 base model without top layer\n    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = False\n\n    # Attention augmented Inception-v3 architecture\n    input_tensor = Input(shape=input_shape)\n    x = base_model(input_tensor)\n    if(attention):\n        x = Concatenate(axis=-1)([spatial_attention(x),x])\n        x = tf.keras.layers.MaxPooling2D()(x)\n        x = Concatenate(axis=-1)([spatial_attention(x),x])\n        x = tf.keras.layers.MaxPooling2D()(x)\n\n    # Add classification layers\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    output_tensor = Dense(num_classes, activation='sigmoid')(x)\n\n    # Create the model\n    model = Model(inputs=input_tensor, outputs=output_tensor)\n    # Freeze the weights of the base model (optional, can be skipped if you want to fine-tune later)\n    #for layer in base_model.layers:\n    #    layer.trainable = False\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:28:33.036906Z","iopub.execute_input":"2023-10-12T15:28:33.037302Z","iopub.status.idle":"2023-10-12T15:28:33.044686Z","shell.execute_reply.started":"2023-10-12T15:28:33.037273Z","shell.execute_reply":"2023-10-12T15:28:33.043508Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, balanced_accuracy_score, average_precision_score, confusion_matrix\n\ndef evaluate_classification(y_true, y_pred, average='macro'):\n    \"\"\"\n    Evaluate the classification performance and calculate micro-average, balanced accuracy, and average precision.\n\n    Parameters:\n        y_true (numpy array or list): True labels.\n        y_pred (numpy array or list): Predicted labels.\n        average (str, optional): The averaging strategy to use for average precision.\n                                 Possible values are 'macro', 'micro', 'weighted', and None.\n                                 Default is 'macro'.\n\n    Returns:\n        report (str): The classification report as a string.\n        balanced_acc (float): The balanced accuracy.\n        avg_precision (float): The average precision.\n        micro_avg_precision (float): The micro-average precision.\n        micro_avg_recall (float): The micro-average recall.\n        micro_avg_f1_score (float): The micro-average F1-score.\n    \"\"\"\n    report = classification_report(y_true, y_pred, output_dict=True, zero_division=1)\n    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n    avg_precision = average_precision_score(y_true, y_pred, average=average)\n\n    # Calculate micro-average precision and recall using confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    tp_sum = np.sum(np.diag(cm))\n    pred_sum = np.sum(cm, axis=0)\n    true_sum = np.sum(cm, axis=1)\n    micro_avg_precision = tp_sum / pred_sum.sum()\n    micro_avg_recall = tp_sum / true_sum.sum()\n    micro_avg_f1_score = 2 * (micro_avg_precision * micro_avg_recall) / (micro_avg_precision + micro_avg_recall)\n\n    return report, balanced_acc, avg_precision, micro_avg_precision, micro_avg_recall, micro_avg_f1_score\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:38:41.267021Z","iopub.execute_input":"2023-10-12T14:38:41.267699Z","iopub.status.idle":"2023-10-12T14:38:41.275240Z","shell.execute_reply.started":"2023-10-12T14:38:41.267669Z","shell.execute_reply":"2023-10-12T14:38:41.274226Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# constant Declaration","metadata":{}},{"cell_type":"code","source":"# 1. Load and split the dataset\ntrain_data_dir = '/kaggle/input/cataract-image-dataset/processed_images/train'\n#validation_data_dir = 'd:/chaman/cataract/test'\ninput_shape = (224, 224)\nbatch_size = 32\nnum_classes=2\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:38:42.787863Z","iopub.execute_input":"2023-10-12T14:38:42.788792Z","iopub.status.idle":"2023-10-12T14:38:42.793950Z","shell.execute_reply.started":"2023-10-12T14:38:42.788749Z","shell.execute_reply":"2023-10-12T14:38:42.793035Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Traing and Validation + Data Augmentation Module","metadata":{}},{"cell_type":"code","source":"# 2. Preprocess the images\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2  # 20% validation split\n)\n\n#validation_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=input_shape,\n    batch_size=batch_size,\n    class_mode='categorical',  # Updated to 'categorical'\n    subset=\"training\"\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=input_shape,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'  # Subset for validation data\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:38:44.501035Z","iopub.execute_input":"2023-10-12T14:38:44.502187Z","iopub.status.idle":"2023-10-12T14:38:44.535484Z","shell.execute_reply.started":"2023-10-12T14:38:44.502146Z","shell.execute_reply":"2023-10-12T14:38:44.534617Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Found 393 images belonging to 2 classes.\nFound 98 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Local MobileNet Model Compilation","metadata":{}},{"cell_type":"code","source":"from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\nfrom keras import backend as K\nfrom keras.activations import sigmoid\nMobileNetModel = create_Local_attention_augmented_mobilenet(input_shape + (3,), num_classes)\n\n# 4. Compile the model\nMobileNetModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:44:59.477244Z","iopub.execute_input":"2023-10-12T14:44:59.477613Z","iopub.status.idle":"2023-10-12T14:45:00.304990Z","shell.execute_reply.started":"2023-10-12T14:44:59.477585Z","shell.execute_reply":"2023-10-12T14:45:00.304041Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Local  InceptionV3 Model Compilation","metadata":{}},{"cell_type":"code","source":"InceptionV3Model = create_Local_Inceptionv3_model(input_shape + (3,), num_classes)\n\nInceptionV3Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:28:39.792902Z","iopub.execute_input":"2023-10-12T15:28:39.793238Z","iopub.status.idle":"2023-10-12T15:28:42.594436Z","shell.execute_reply.started":"2023-10-12T15:28:39.793213Z","shell.execute_reply":"2023-10-12T15:28:42.593420Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',  # Monitor validation loss\n    patience=40,          # Number of epochs with no improvement to wait\n    restore_best_weights=True,  # Restore the best model weights when stopping\n\n)\ncp_callback1 = tf.keras.callbacks.ModelCheckpoint('./fpseweights.h5', save_weights_only=True, verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:39:27.094354Z","iopub.execute_input":"2023-10-12T14:39:27.094734Z","iopub.status.idle":"2023-10-12T14:39:27.100244Z","shell.execute_reply.started":"2023-10-12T14:39:27.094707Z","shell.execute_reply":"2023-10-12T14:39:27.099359Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"cp_callback2 = tf.keras.callbacks.ModelCheckpoint('./fpseweights1.h5', save_weights_only=True, verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:39:27.780813Z","iopub.execute_input":"2023-10-12T14:39:27.781488Z","iopub.status.idle":"2023-10-12T14:39:27.786605Z","shell.execute_reply.started":"2023-10-12T14:39:27.781416Z","shell.execute_reply":"2023-10-12T14:39:27.785642Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"cp_callback3 = tf.keras.callbacks.ModelCheckpoint('./fpseweights2.h5', save_weights_only=True, verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:39:28.563200Z","iopub.execute_input":"2023-10-12T14:39:28.563560Z","iopub.status.idle":"2023-10-12T14:39:28.568504Z","shell.execute_reply.started":"2023-10-12T14:39:28.563532Z","shell.execute_reply":"2023-10-12T14:39:28.567348Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Local MobileNet Model Training","metadata":{}},{"cell_type":"code","source":"# 5. Train the model\nepochs = 100\n\n# Create a directory to save the best model weights during training\nos.makedirs('models', exist_ok=True)\nmodel_checkpoint = ModelCheckpoint('models/best_localmobilnetmodel1.h5', save_best_only=True, save_weights_only=True)\n\nhistory = MobileNetModel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[model_checkpoint,cp_callback1]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T14:45:05.118167Z","iopub.execute_input":"2023-10-12T14:45:05.118526Z","iopub.status.idle":"2023-10-12T15:17:53.817446Z","shell.execute_reply.started":"2023-10-12T14:45:05.118492Z","shell.execute_reply":"2023-10-12T15:17:53.816428Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/100\n12/12 [==============================] - ETA: 0s - loss: 8.7856 - accuracy: 0.5789\nEpoch 1: val_loss did not improve from 0.09931\n12/12 [==============================] - 21s 2s/step - loss: 8.7856 - accuracy: 0.5789 - val_loss: 0.7756 - val_accuracy: 0.8125\nEpoch 2/100\n12/12 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.8587\nEpoch 2: val_loss did not improve from 0.09931\n12/12 [==============================] - 18s 2s/step - loss: 0.6344 - accuracy: 0.8587 - val_loss: 0.7840 - val_accuracy: 0.8229\nEpoch 3/100\n12/12 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.9114\nEpoch 3: val_loss did not improve from 0.09931\n12/12 [==============================] - 18s 1s/step - loss: 0.4327 - accuracy: 0.9114 - val_loss: 0.1494 - val_accuracy: 0.9479\nEpoch 4/100\n12/12 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9224\nEpoch 4: val_loss did not improve from 0.09931\n12/12 [==============================] - 19s 2s/step - loss: 0.2528 - accuracy: 0.9224 - val_loss: 0.1956 - val_accuracy: 0.9479\nEpoch 5/100\n12/12 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.9224\nEpoch 5: val_loss did not improve from 0.09931\n12/12 [==============================] - 20s 2s/step - loss: 0.2929 - accuracy: 0.9224 - val_loss: 0.2889 - val_accuracy: 0.9167\nEpoch 6/100\n12/12 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.9224\nEpoch 6: val_loss did not improve from 0.09931\n12/12 [==============================] - 17s 1s/step - loss: 0.2894 - accuracy: 0.9224 - val_loss: 0.4535 - val_accuracy: 0.8750\nEpoch 7/100\n12/12 [==============================] - ETA: 0s - loss: 0.2817 - accuracy: 0.9224\nEpoch 7: val_loss improved from 0.09931 to 0.09871, saving model to ./fpseweights.h5\n12/12 [==============================] - 19s 2s/step - loss: 0.2817 - accuracy: 0.9224 - val_loss: 0.0987 - val_accuracy: 0.9688\nEpoch 8/100\n12/12 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9529\nEpoch 8: val_loss did not improve from 0.09871\n12/12 [==============================] - 18s 2s/step - loss: 0.1539 - accuracy: 0.9529 - val_loss: 0.1151 - val_accuracy: 0.9583\nEpoch 9/100\n12/12 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9446\nEpoch 9: val_loss improved from 0.09871 to 0.09310, saving model to ./fpseweights.h5\n12/12 [==============================] - 19s 2s/step - loss: 0.1536 - accuracy: 0.9446 - val_loss: 0.0931 - val_accuracy: 0.9688\nEpoch 10/100\n12/12 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9391\nEpoch 10: val_loss did not improve from 0.09310\n12/12 [==============================] - 20s 2s/step - loss: 0.1605 - accuracy: 0.9391 - val_loss: 0.1191 - val_accuracy: 0.9688\nEpoch 11/100\n12/12 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.9252\nEpoch 11: val_loss did not improve from 0.09310\n12/12 [==============================] - 18s 2s/step - loss: 0.2085 - accuracy: 0.9252 - val_loss: 0.0948 - val_accuracy: 0.9479\nEpoch 12/100\n12/12 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9474\nEpoch 12: val_loss did not improve from 0.09310\n12/12 [==============================] - 17s 1s/step - loss: 0.1509 - accuracy: 0.9474 - val_loss: 0.1114 - val_accuracy: 0.9583\nEpoch 13/100\n12/12 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9363\nEpoch 13: val_loss did not improve from 0.09310\n12/12 [==============================] - 20s 2s/step - loss: 0.1491 - accuracy: 0.9363 - val_loss: 0.0956 - val_accuracy: 0.9688\nEpoch 14/100\n12/12 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9668\nEpoch 14: val_loss improved from 0.09310 to 0.08410, saving model to ./fpseweights.h5\n12/12 [==============================] - 17s 2s/step - loss: 0.0919 - accuracy: 0.9668 - val_loss: 0.0841 - val_accuracy: 0.9688\nEpoch 15/100\n12/12 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9280\nEpoch 15: val_loss did not improve from 0.08410\n12/12 [==============================] - 20s 2s/step - loss: 0.1704 - accuracy: 0.9280 - val_loss: 0.3476 - val_accuracy: 0.8438\nEpoch 16/100\n12/12 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9474\nEpoch 16: val_loss did not improve from 0.08410\n12/12 [==============================] - 20s 2s/step - loss: 0.1447 - accuracy: 0.9474 - val_loss: 0.1128 - val_accuracy: 0.9688\nEpoch 17/100\n12/12 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9446\nEpoch 17: val_loss did not improve from 0.08410\n12/12 [==============================] - 19s 2s/step - loss: 0.1362 - accuracy: 0.9446 - val_loss: 0.1001 - val_accuracy: 0.9583\nEpoch 18/100\n12/12 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9501\nEpoch 18: val_loss did not improve from 0.08410\n12/12 [==============================] - 18s 2s/step - loss: 0.1524 - accuracy: 0.9501 - val_loss: 0.1518 - val_accuracy: 0.9479\nEpoch 19/100\n12/12 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.9584\nEpoch 19: val_loss did not improve from 0.08410\n12/12 [==============================] - 17s 1s/step - loss: 0.1260 - accuracy: 0.9584 - val_loss: 0.1615 - val_accuracy: 0.9375\nEpoch 20/100\n12/12 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9557\nEpoch 20: val_loss improved from 0.08410 to 0.04835, saving model to ./fpseweights.h5\n12/12 [==============================] - 17s 1s/step - loss: 0.1195 - accuracy: 0.9557 - val_loss: 0.0484 - val_accuracy: 0.9688\nEpoch 21/100\n12/12 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9584\nEpoch 21: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0946 - accuracy: 0.9584 - val_loss: 0.0697 - val_accuracy: 0.9583\nEpoch 22/100\n12/12 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9609\nEpoch 22: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.1009 - accuracy: 0.9609 - val_loss: 0.0499 - val_accuracy: 0.9792\nEpoch 23/100\n12/12 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9806\nEpoch 23: val_loss did not improve from 0.04835\n12/12 [==============================] - 20s 2s/step - loss: 0.0849 - accuracy: 0.9806 - val_loss: 0.0577 - val_accuracy: 0.9896\nEpoch 24/100\n12/12 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9612\nEpoch 24: val_loss did not improve from 0.04835\n12/12 [==============================] - 17s 1s/step - loss: 0.1137 - accuracy: 0.9612 - val_loss: 0.0862 - val_accuracy: 0.9792\nEpoch 25/100\n12/12 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9714\nEpoch 25: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0634 - accuracy: 0.9714 - val_loss: 0.0571 - val_accuracy: 0.9792\nEpoch 26/100\n12/12 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9640\nEpoch 26: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0972 - accuracy: 0.9640 - val_loss: 0.1281 - val_accuracy: 0.9375\nEpoch 27/100\n12/12 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9695\nEpoch 27: val_loss did not improve from 0.04835\n12/12 [==============================] - 17s 2s/step - loss: 0.0769 - accuracy: 0.9695 - val_loss: 0.1002 - val_accuracy: 0.9479\nEpoch 28/100\n12/12 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9751\nEpoch 28: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0746 - accuracy: 0.9751 - val_loss: 0.1447 - val_accuracy: 0.9375\nEpoch 29/100\n12/12 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9751\nEpoch 29: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 1s/step - loss: 0.0500 - accuracy: 0.9751 - val_loss: 0.1933 - val_accuracy: 0.9167\nEpoch 30/100\n12/12 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9584\nEpoch 30: val_loss did not improve from 0.04835\n12/12 [==============================] - 20s 2s/step - loss: 0.1159 - accuracy: 0.9584 - val_loss: 0.1311 - val_accuracy: 0.9375\nEpoch 31/100\n12/12 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9723\nEpoch 31: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0729 - accuracy: 0.9723 - val_loss: 0.1856 - val_accuracy: 0.9271\nEpoch 32/100\n12/12 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9557\nEpoch 32: val_loss did not improve from 0.04835\n12/12 [==============================] - 20s 2s/step - loss: 0.1184 - accuracy: 0.9557 - val_loss: 0.1127 - val_accuracy: 0.9375\nEpoch 33/100\n12/12 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9723\nEpoch 33: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0667 - accuracy: 0.9723 - val_loss: 0.1817 - val_accuracy: 0.9271\nEpoch 34/100\n12/12 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.9474\nEpoch 34: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.1225 - accuracy: 0.9474 - val_loss: 0.1217 - val_accuracy: 0.9375\nEpoch 35/100\n12/12 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9584\nEpoch 35: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.1363 - accuracy: 0.9584 - val_loss: 0.1547 - val_accuracy: 0.9167\nEpoch 36/100\n12/12 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9557\nEpoch 36: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 1s/step - loss: 0.1263 - accuracy: 0.9557 - val_loss: 0.0769 - val_accuracy: 0.9896\nEpoch 37/100\n12/12 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9474\nEpoch 37: val_loss did not improve from 0.04835\n12/12 [==============================] - 20s 2s/step - loss: 0.1570 - accuracy: 0.9474 - val_loss: 0.1601 - val_accuracy: 0.9479\nEpoch 38/100\n12/12 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9612\nEpoch 38: val_loss did not improve from 0.04835\n12/12 [==============================] - 20s 2s/step - loss: 0.0849 - accuracy: 0.9612 - val_loss: 0.1357 - val_accuracy: 0.9479\nEpoch 39/100\n12/12 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9668\nEpoch 39: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0785 - accuracy: 0.9668 - val_loss: 0.1061 - val_accuracy: 0.9271\nEpoch 40/100\n12/12 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9766\nEpoch 40: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: 0.0496 - val_accuracy: 0.9792\nEpoch 41/100\n12/12 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9723\nEpoch 41: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0785 - accuracy: 0.9723 - val_loss: 0.1142 - val_accuracy: 0.9688\nEpoch 42/100\n12/12 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9806\nEpoch 42: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0666 - accuracy: 0.9806 - val_loss: 0.1099 - val_accuracy: 0.9479\nEpoch 43/100\n12/12 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9723\nEpoch 43: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0604 - accuracy: 0.9723 - val_loss: 0.1743 - val_accuracy: 0.9375\nEpoch 44/100\n12/12 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9751\nEpoch 44: val_loss did not improve from 0.04835\n12/12 [==============================] - 20s 2s/step - loss: 0.0967 - accuracy: 0.9751 - val_loss: 0.1472 - val_accuracy: 0.9062\nEpoch 45/100\n12/12 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9695\nEpoch 45: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0786 - accuracy: 0.9695 - val_loss: 0.1529 - val_accuracy: 0.9479\nEpoch 46/100\n12/12 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9446\nEpoch 46: val_loss did not improve from 0.04835\n12/12 [==============================] - 20s 2s/step - loss: 0.1303 - accuracy: 0.9446 - val_loss: 0.1037 - val_accuracy: 0.9479\nEpoch 47/100\n12/12 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9818\nEpoch 47: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0572 - accuracy: 0.9818 - val_loss: 0.1505 - val_accuracy: 0.9583\nEpoch 48/100\n12/12 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9751\nEpoch 48: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0547 - accuracy: 0.9751 - val_loss: 0.1200 - val_accuracy: 0.9479\nEpoch 49/100\n12/12 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9197\nEpoch 49: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.2323 - accuracy: 0.9197 - val_loss: 0.1576 - val_accuracy: 0.9375\nEpoch 50/100\n12/12 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9612\nEpoch 50: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0959 - accuracy: 0.9612 - val_loss: 0.1596 - val_accuracy: 0.9479\nEpoch 51/100\n12/12 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8864\nEpoch 51: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.3290 - accuracy: 0.8864 - val_loss: 0.4889 - val_accuracy: 0.8021\nEpoch 52/100\n12/12 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9307\nEpoch 52: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.2359 - accuracy: 0.9307 - val_loss: 0.3597 - val_accuracy: 0.8750\nEpoch 53/100\n12/12 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9363\nEpoch 53: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.1525 - accuracy: 0.9363 - val_loss: 0.1405 - val_accuracy: 0.9271\nEpoch 54/100\n12/12 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9695\nEpoch 54: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0798 - accuracy: 0.9695 - val_loss: 0.0892 - val_accuracy: 0.9479\nEpoch 55/100\n12/12 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9806\nEpoch 55: val_loss did not improve from 0.04835\n12/12 [==============================] - 17s 1s/step - loss: 0.0683 - accuracy: 0.9806 - val_loss: 0.0986 - val_accuracy: 0.9583\nEpoch 56/100\n12/12 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9806\nEpoch 56: val_loss did not improve from 0.04835\n12/12 [==============================] - 19s 2s/step - loss: 0.0355 - accuracy: 0.9806 - val_loss: 0.0859 - val_accuracy: 0.9583\nEpoch 57/100\n12/12 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9723\nEpoch 57: val_loss did not improve from 0.04835\n12/12 [==============================] - 18s 2s/step - loss: 0.0684 - accuracy: 0.9723 - val_loss: 0.0955 - val_accuracy: 0.9375\nEpoch 58/100\n12/12 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9917\nEpoch 58: val_loss did not improve from 0.04835\n12/12 [==============================] - 17s 1s/step - loss: 0.0482 - accuracy: 0.9917 - val_loss: 0.0625 - val_accuracy: 0.9792\nEpoch 59/100\n12/12 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9806\nEpoch 59: val_loss did not improve from 0.04835\n12/12 [==============================] - 21s 2s/step - loss: 0.0777 - accuracy: 0.9806 - val_loss: 0.1060 - val_accuracy: 0.9688\nEpoch 60/100\n12/12 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9861\nEpoch 60: val_loss improved from 0.04835 to 0.02958, saving model to ./fpseweights.h5\n12/12 [==============================] - 18s 1s/step - loss: 0.0527 - accuracy: 0.9861 - val_loss: 0.0296 - val_accuracy: 0.9896\nEpoch 61/100\n12/12 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9688\nEpoch 61: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0708 - accuracy: 0.9688 - val_loss: 0.0655 - val_accuracy: 0.9688\nEpoch 62/100\n12/12 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9861\nEpoch 62: val_loss did not improve from 0.02958\n12/12 [==============================] - 19s 2s/step - loss: 0.0613 - accuracy: 0.9861 - val_loss: 0.1464 - val_accuracy: 0.9583\nEpoch 63/100\n12/12 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9870\nEpoch 63: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.1049 - val_accuracy: 0.9688\nEpoch 64/100\n12/12 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9751\nEpoch 64: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0538 - accuracy: 0.9751 - val_loss: 0.1888 - val_accuracy: 0.9375\nEpoch 65/100\n12/12 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9806\nEpoch 65: val_loss did not improve from 0.02958\n12/12 [==============================] - 19s 2s/step - loss: 0.0467 - accuracy: 0.9806 - val_loss: 0.1769 - val_accuracy: 0.9479\nEpoch 66/100\n12/12 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9834\nEpoch 66: val_loss did not improve from 0.02958\n12/12 [==============================] - 21s 2s/step - loss: 0.0426 - accuracy: 0.9834 - val_loss: 0.0971 - val_accuracy: 0.9479\nEpoch 67/100\n12/12 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9834\nEpoch 67: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 2s/step - loss: 0.0389 - accuracy: 0.9834 - val_loss: 0.1541 - val_accuracy: 0.9583\nEpoch 68/100\n12/12 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9861\nEpoch 68: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0468 - accuracy: 0.9861 - val_loss: 0.1350 - val_accuracy: 0.9583\nEpoch 69/100\n12/12 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9834\nEpoch 69: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 2s/step - loss: 0.0470 - accuracy: 0.9834 - val_loss: 0.0578 - val_accuracy: 0.9896\nEpoch 70/100\n12/12 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9723\nEpoch 70: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0886 - accuracy: 0.9723 - val_loss: 0.1304 - val_accuracy: 0.9479\nEpoch 71/100\n12/12 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9806\nEpoch 71: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0413 - accuracy: 0.9806 - val_loss: 0.0599 - val_accuracy: 0.9792\nEpoch 72/100\n12/12 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9778\nEpoch 72: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0556 - accuracy: 0.9778 - val_loss: 0.1113 - val_accuracy: 0.9583\nEpoch 73/100\n12/12 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9751\nEpoch 73: val_loss did not improve from 0.02958\n12/12 [==============================] - 19s 2s/step - loss: 0.0499 - accuracy: 0.9751 - val_loss: 0.1993 - val_accuracy: 0.9271\nEpoch 74/100\n12/12 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9861\nEpoch 74: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0549 - accuracy: 0.9861 - val_loss: 0.1729 - val_accuracy: 0.9271\nEpoch 75/100\n12/12 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9778\nEpoch 75: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0654 - accuracy: 0.9778 - val_loss: 0.2414 - val_accuracy: 0.9375\nEpoch 76/100\n12/12 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9834\nEpoch 76: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.1255 - val_accuracy: 0.9479\nEpoch 77/100\n12/12 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9861\nEpoch 77: val_loss did not improve from 0.02958\n12/12 [==============================] - 19s 2s/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.1820 - val_accuracy: 0.9479\nEpoch 78/100\n12/12 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9896\nEpoch 78: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0506 - accuracy: 0.9896 - val_loss: 0.1504 - val_accuracy: 0.9583\nEpoch 79/100\n12/12 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9723\nEpoch 79: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0619 - accuracy: 0.9723 - val_loss: 0.1506 - val_accuracy: 0.9479\nEpoch 80/100\n12/12 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9889\nEpoch 80: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0336 - accuracy: 0.9889 - val_loss: 0.0936 - val_accuracy: 0.9688\nEpoch 81/100\n12/12 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9945\nEpoch 81: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0247 - accuracy: 0.9945 - val_loss: 0.0361 - val_accuracy: 0.9896\nEpoch 82/100\n12/12 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9751\nEpoch 82: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0672 - accuracy: 0.9751 - val_loss: 0.0523 - val_accuracy: 0.9792\nEpoch 83/100\n12/12 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9806\nEpoch 83: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 1s/step - loss: 0.0430 - accuracy: 0.9806 - val_loss: 0.1074 - val_accuracy: 0.9583\nEpoch 84/100\n12/12 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9818\nEpoch 84: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0610 - accuracy: 0.9818 - val_loss: 0.0437 - val_accuracy: 0.9896\nEpoch 85/100\n12/12 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9818\nEpoch 85: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0554 - accuracy: 0.9818 - val_loss: 0.0341 - val_accuracy: 1.0000\nEpoch 86/100\n12/12 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9806\nEpoch 86: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0449 - accuracy: 0.9806 - val_loss: 0.1209 - val_accuracy: 0.9583\nEpoch 87/100\n12/12 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9889\nEpoch 87: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.0904 - val_accuracy: 0.9688\nEpoch 88/100\n12/12 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9945\nEpoch 88: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0256 - accuracy: 0.9945 - val_loss: 0.1205 - val_accuracy: 0.9479\nEpoch 89/100\n12/12 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9861\nEpoch 89: val_loss did not improve from 0.02958\n12/12 [==============================] - 19s 2s/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 0.1223 - val_accuracy: 0.9583\nEpoch 90/100\n12/12 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9917\nEpoch 90: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0199 - accuracy: 0.9917 - val_loss: 0.0648 - val_accuracy: 0.9896\nEpoch 91/100\n12/12 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9806\nEpoch 91: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0492 - accuracy: 0.9806 - val_loss: 0.3005 - val_accuracy: 0.9167\nEpoch 92/100\n12/12 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9751\nEpoch 92: val_loss did not improve from 0.02958\n12/12 [==============================] - 19s 2s/step - loss: 0.0554 - accuracy: 0.9751 - val_loss: 0.0673 - val_accuracy: 0.9792\nEpoch 93/100\n12/12 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9778\nEpoch 93: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 1s/step - loss: 0.0684 - accuracy: 0.9778 - val_loss: 0.0941 - val_accuracy: 0.9688\nEpoch 94/100\n12/12 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9917\nEpoch 94: val_loss did not improve from 0.02958\n12/12 [==============================] - 17s 1s/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.0364 - val_accuracy: 0.9792\nEpoch 95/100\n12/12 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9834\nEpoch 95: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0527 - accuracy: 0.9834 - val_loss: 0.0822 - val_accuracy: 0.9583\nEpoch 96/100\n12/12 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9806\nEpoch 96: val_loss did not improve from 0.02958\n12/12 [==============================] - 20s 2s/step - loss: 0.0539 - accuracy: 0.9806 - val_loss: 0.2171 - val_accuracy: 0.9479\nEpoch 97/100\n12/12 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9723\nEpoch 97: val_loss did not improve from 0.02958\n12/12 [==============================] - 19s 2s/step - loss: 0.0655 - accuracy: 0.9723 - val_loss: 0.1280 - val_accuracy: 0.9479\nEpoch 98/100\n12/12 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9834\nEpoch 98: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 1s/step - loss: 0.0414 - accuracy: 0.9834 - val_loss: 0.0406 - val_accuracy: 0.9896\nEpoch 99/100\n12/12 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9889\nEpoch 99: val_loss did not improve from 0.02958\n12/12 [==============================] - 18s 2s/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.1632 - val_accuracy: 0.9375\nEpoch 100/100\n12/12 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9834\nEpoch 100: val_loss did not improve from 0.02958\n12/12 [==============================] - 21s 2s/step - loss: 0.0497 - accuracy: 0.9834 - val_loss: 0.0467 - val_accuracy: 0.9792\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Local InceptionV3 Model Training","metadata":{}},{"cell_type":"code","source":"# Create a directory to save the best model weights during training\nos.makedirs('models', exist_ok=True)\nmodel_checkpoint = ModelCheckpoint('models/best_LocalInceptionModel1.h5', save_best_only=True, save_weights_only=True)\n\nInceptionV3history = InceptionV3Model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[model_checkpoint,cp_callback2]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:28:48.862736Z","iopub.execute_input":"2023-10-12T15:28:48.863074Z","iopub.status.idle":"2023-10-12T16:02:41.982900Z","shell.execute_reply.started":"2023-10-12T15:28:48.863048Z","shell.execute_reply":"2023-10-12T16:02:41.981923Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1/100\n12/12 [==============================] - ETA: 0s - loss: 22.5567 - accuracy: 0.5208\nEpoch 1: val_loss improved from inf to 1.29505, saving model to ./fpseweights1.h5\n12/12 [==============================] - 27s 2s/step - loss: 22.5567 - accuracy: 0.5208 - val_loss: 1.2951 - val_accuracy: 0.8854\nEpoch 2/100\n12/12 [==============================] - ETA: 0s - loss: 2.3108 - accuracy: 0.7784\nEpoch 2: val_loss did not improve from 1.29505\n12/12 [==============================] - 17s 1s/step - loss: 2.3108 - accuracy: 0.7784 - val_loss: 1.6057 - val_accuracy: 0.8646\nEpoch 3/100\n12/12 [==============================] - ETA: 0s - loss: 1.1217 - accuracy: 0.8726\nEpoch 3: val_loss improved from 1.29505 to 0.93759, saving model to ./fpseweights1.h5\n12/12 [==============================] - 19s 2s/step - loss: 1.1217 - accuracy: 0.8726 - val_loss: 0.9376 - val_accuracy: 0.8646\nEpoch 4/100\n12/12 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.8532\nEpoch 4: val_loss improved from 0.93759 to 0.18425, saving model to ./fpseweights1.h5\n12/12 [==============================] - 19s 2s/step - loss: 0.7573 - accuracy: 0.8532 - val_loss: 0.1842 - val_accuracy: 0.9271\nEpoch 5/100\n12/12 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.8643\nEpoch 5: val_loss did not improve from 0.18425\n12/12 [==============================] - 19s 2s/step - loss: 0.4566 - accuracy: 0.8643 - val_loss: 0.2387 - val_accuracy: 0.9062\nEpoch 6/100\n12/12 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9280\nEpoch 6: val_loss did not improve from 0.18425\n12/12 [==============================] - 18s 2s/step - loss: 0.2308 - accuracy: 0.9280 - val_loss: 0.1860 - val_accuracy: 0.9167\nEpoch 7/100\n12/12 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9086\nEpoch 7: val_loss improved from 0.18425 to 0.14540, saving model to ./fpseweights1.h5\n12/12 [==============================] - 20s 2s/step - loss: 0.2346 - accuracy: 0.9086 - val_loss: 0.1454 - val_accuracy: 0.9479\nEpoch 8/100\n12/12 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.9030\nEpoch 8: val_loss did not improve from 0.14540\n12/12 [==============================] - 18s 2s/step - loss: 0.2669 - accuracy: 0.9030 - val_loss: 0.1656 - val_accuracy: 0.9062\nEpoch 9/100\n12/12 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.8033\nEpoch 9: val_loss did not improve from 0.14540\n12/12 [==============================] - 18s 1s/step - loss: 0.7078 - accuracy: 0.8033 - val_loss: 0.2977 - val_accuracy: 0.9271\nEpoch 10/100\n12/12 [==============================] - ETA: 0s - loss: 0.5627 - accuracy: 0.8698\nEpoch 10: val_loss did not improve from 0.14540\n12/12 [==============================] - 17s 1s/step - loss: 0.5627 - accuracy: 0.8698 - val_loss: 0.1949 - val_accuracy: 0.9271\nEpoch 11/100\n12/12 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.9335\nEpoch 11: val_loss did not improve from 0.14540\n12/12 [==============================] - 18s 2s/step - loss: 0.1901 - accuracy: 0.9335 - val_loss: 0.2993 - val_accuracy: 0.9271\nEpoch 12/100\n12/12 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.9086\nEpoch 12: val_loss did not improve from 0.14540\n12/12 [==============================] - 19s 2s/step - loss: 0.3178 - accuracy: 0.9086 - val_loss: 0.6439 - val_accuracy: 0.8646\nEpoch 13/100\n12/12 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.9169\nEpoch 13: val_loss improved from 0.14540 to 0.10314, saving model to ./fpseweights1.h5\n12/12 [==============================] - 20s 2s/step - loss: 0.2760 - accuracy: 0.9169 - val_loss: 0.1031 - val_accuracy: 0.9479\nEpoch 14/100\n12/12 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9335\nEpoch 14: val_loss did not improve from 0.10314\n12/12 [==============================] - 20s 2s/step - loss: 0.1566 - accuracy: 0.9335 - val_loss: 0.1703 - val_accuracy: 0.9167\nEpoch 15/100\n12/12 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9335\nEpoch 15: val_loss did not improve from 0.10314\n12/12 [==============================] - 20s 2s/step - loss: 0.1995 - accuracy: 0.9335 - val_loss: 0.1768 - val_accuracy: 0.9375\nEpoch 16/100\n12/12 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9335\nEpoch 16: val_loss did not improve from 0.10314\n12/12 [==============================] - 20s 2s/step - loss: 0.1699 - accuracy: 0.9335 - val_loss: 0.1124 - val_accuracy: 0.9688\nEpoch 17/100\n12/12 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.9058\nEpoch 17: val_loss did not improve from 0.10314\n12/12 [==============================] - 20s 2s/step - loss: 0.2205 - accuracy: 0.9058 - val_loss: 0.1709 - val_accuracy: 0.9375\nEpoch 18/100\n12/12 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9557\nEpoch 18: val_loss did not improve from 0.10314\n12/12 [==============================] - 20s 2s/step - loss: 0.1263 - accuracy: 0.9557 - val_loss: 0.2362 - val_accuracy: 0.9271\nEpoch 19/100\n12/12 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9479\nEpoch 19: val_loss did not improve from 0.10314\n12/12 [==============================] - 19s 1s/step - loss: 0.1473 - accuracy: 0.9479 - val_loss: 0.1975 - val_accuracy: 0.9375\nEpoch 20/100\n12/12 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9474\nEpoch 20: val_loss did not improve from 0.10314\n12/12 [==============================] - 18s 2s/step - loss: 0.1817 - accuracy: 0.9474 - val_loss: 0.1365 - val_accuracy: 0.9375\nEpoch 21/100\n12/12 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9640\nEpoch 21: val_loss improved from 0.10314 to 0.09901, saving model to ./fpseweights1.h5\n12/12 [==============================] - 19s 2s/step - loss: 0.1009 - accuracy: 0.9640 - val_loss: 0.0990 - val_accuracy: 0.9583\nEpoch 22/100\n12/12 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9557\nEpoch 22: val_loss did not improve from 0.09901\n12/12 [==============================] - 18s 2s/step - loss: 0.1098 - accuracy: 0.9557 - val_loss: 0.1581 - val_accuracy: 0.9062\nEpoch 23/100\n12/12 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9668\nEpoch 23: val_loss did not improve from 0.09901\n12/12 [==============================] - 20s 2s/step - loss: 0.1150 - accuracy: 0.9668 - val_loss: 0.1069 - val_accuracy: 0.9479\nEpoch 24/100\n12/12 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9695\nEpoch 24: val_loss did not improve from 0.09901\n12/12 [==============================] - 19s 2s/step - loss: 0.1123 - accuracy: 0.9695 - val_loss: 0.1315 - val_accuracy: 0.9479\nEpoch 25/100\n12/12 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9501\nEpoch 25: val_loss did not improve from 0.09901\n12/12 [==============================] - 19s 2s/step - loss: 0.1273 - accuracy: 0.9501 - val_loss: 0.1429 - val_accuracy: 0.9479\nEpoch 26/100\n12/12 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9501\nEpoch 26: val_loss did not improve from 0.09901\n12/12 [==============================] - 18s 1s/step - loss: 0.1166 - accuracy: 0.9501 - val_loss: 0.1433 - val_accuracy: 0.9583\nEpoch 27/100\n12/12 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9612\nEpoch 27: val_loss did not improve from 0.09901\n12/12 [==============================] - 18s 2s/step - loss: 0.0969 - accuracy: 0.9612 - val_loss: 0.1308 - val_accuracy: 0.9479\nEpoch 28/100\n12/12 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9427\nEpoch 28: val_loss improved from 0.09901 to 0.06784, saving model to ./fpseweights1.h5\n12/12 [==============================] - 20s 2s/step - loss: 0.1485 - accuracy: 0.9427 - val_loss: 0.0678 - val_accuracy: 0.9688\nEpoch 29/100\n12/12 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9668\nEpoch 29: val_loss did not improve from 0.06784\n12/12 [==============================] - 18s 1s/step - loss: 0.1101 - accuracy: 0.9668 - val_loss: 0.1103 - val_accuracy: 0.9688\nEpoch 30/100\n12/12 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.9003\nEpoch 30: val_loss did not improve from 0.06784\n12/12 [==============================] - 18s 1s/step - loss: 0.2807 - accuracy: 0.9003 - val_loss: 0.1368 - val_accuracy: 0.9375\nEpoch 31/100\n12/12 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.8476\nEpoch 31: val_loss did not improve from 0.06784\n12/12 [==============================] - 17s 1s/step - loss: 0.4621 - accuracy: 0.8476 - val_loss: 0.2739 - val_accuracy: 0.8958\nEpoch 32/100\n12/12 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.9058\nEpoch 32: val_loss did not improve from 0.06784\n12/12 [==============================] - 18s 1s/step - loss: 0.3774 - accuracy: 0.9058 - val_loss: 0.3210 - val_accuracy: 0.9271\nEpoch 33/100\n12/12 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9335\nEpoch 33: val_loss did not improve from 0.06784\n12/12 [==============================] - 19s 2s/step - loss: 0.1835 - accuracy: 0.9335 - val_loss: 0.0984 - val_accuracy: 0.9583\nEpoch 34/100\n12/12 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9612\nEpoch 34: val_loss did not improve from 0.06784\n12/12 [==============================] - 18s 2s/step - loss: 0.1422 - accuracy: 0.9612 - val_loss: 0.1611 - val_accuracy: 0.9583\nEpoch 35/100\n12/12 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9505\nEpoch 35: val_loss did not improve from 0.06784\n12/12 [==============================] - 20s 2s/step - loss: 0.1604 - accuracy: 0.9505 - val_loss: 0.2931 - val_accuracy: 0.8854\nEpoch 36/100\n12/12 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9446\nEpoch 36: val_loss did not improve from 0.06784\n12/12 [==============================] - 19s 2s/step - loss: 0.1782 - accuracy: 0.9446 - val_loss: 0.1296 - val_accuracy: 0.9271\nEpoch 37/100\n12/12 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9363\nEpoch 37: val_loss did not improve from 0.06784\n12/12 [==============================] - 20s 2s/step - loss: 0.1806 - accuracy: 0.9363 - val_loss: 0.1487 - val_accuracy: 0.9583\nEpoch 38/100\n12/12 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9529\nEpoch 38: val_loss did not improve from 0.06784\n12/12 [==============================] - 17s 1s/step - loss: 0.1365 - accuracy: 0.9529 - val_loss: 0.1613 - val_accuracy: 0.9271\nEpoch 39/100\n12/12 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9501\nEpoch 39: val_loss did not improve from 0.06784\n12/12 [==============================] - 19s 2s/step - loss: 0.1538 - accuracy: 0.9501 - val_loss: 0.2109 - val_accuracy: 0.9167\nEpoch 40/100\n12/12 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9557\nEpoch 40: val_loss did not improve from 0.06784\n12/12 [==============================] - 20s 2s/step - loss: 0.1431 - accuracy: 0.9557 - val_loss: 0.0932 - val_accuracy: 0.9688\nEpoch 41/100\n12/12 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9418\nEpoch 41: val_loss improved from 0.06784 to 0.04827, saving model to ./fpseweights1.h5\n12/12 [==============================] - 18s 2s/step - loss: 0.1591 - accuracy: 0.9418 - val_loss: 0.0483 - val_accuracy: 0.9792\nEpoch 42/100\n12/12 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9751\nEpoch 42: val_loss did not improve from 0.04827\n12/12 [==============================] - 18s 1s/step - loss: 0.0716 - accuracy: 0.9751 - val_loss: 0.1780 - val_accuracy: 0.9479\nEpoch 43/100\n12/12 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9635\nEpoch 43: val_loss did not improve from 0.04827\n12/12 [==============================] - 18s 2s/step - loss: 0.1199 - accuracy: 0.9635 - val_loss: 0.1508 - val_accuracy: 0.9375\nEpoch 44/100\n12/12 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9695\nEpoch 44: val_loss did not improve from 0.04827\n12/12 [==============================] - 17s 1s/step - loss: 0.0950 - accuracy: 0.9695 - val_loss: 0.1096 - val_accuracy: 0.9271\nEpoch 45/100\n12/12 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9723\nEpoch 45: val_loss did not improve from 0.04827\n12/12 [==============================] - 18s 2s/step - loss: 0.0660 - accuracy: 0.9723 - val_loss: 0.1285 - val_accuracy: 0.9271\nEpoch 46/100\n12/12 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9640\nEpoch 46: val_loss did not improve from 0.04827\n12/12 [==============================] - 17s 1s/step - loss: 0.1001 - accuracy: 0.9640 - val_loss: 0.2834 - val_accuracy: 0.8854\nEpoch 47/100\n12/12 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9391\nEpoch 47: val_loss did not improve from 0.04827\n12/12 [==============================] - 20s 2s/step - loss: 0.1387 - accuracy: 0.9391 - val_loss: 0.0606 - val_accuracy: 0.9896\nEpoch 48/100\n12/12 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9335\nEpoch 48: val_loss did not improve from 0.04827\n12/12 [==============================] - 20s 2s/step - loss: 0.2050 - accuracy: 0.9335 - val_loss: 0.2513 - val_accuracy: 0.9167\nEpoch 49/100\n12/12 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9529\nEpoch 49: val_loss did not improve from 0.04827\n12/12 [==============================] - 20s 2s/step - loss: 0.1291 - accuracy: 0.9529 - val_loss: 0.2109 - val_accuracy: 0.9271\nEpoch 50/100\n12/12 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9474\nEpoch 50: val_loss did not improve from 0.04827\n12/12 [==============================] - 18s 1s/step - loss: 0.1200 - accuracy: 0.9474 - val_loss: 0.1043 - val_accuracy: 0.9479\nEpoch 51/100\n12/12 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9778\nEpoch 51: val_loss did not improve from 0.04827\n12/12 [==============================] - 17s 2s/step - loss: 0.0692 - accuracy: 0.9778 - val_loss: 0.1619 - val_accuracy: 0.9479\nEpoch 52/100\n12/12 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9557\nEpoch 52: val_loss did not improve from 0.04827\n12/12 [==============================] - 20s 2s/step - loss: 0.1456 - accuracy: 0.9557 - val_loss: 0.2746 - val_accuracy: 0.9167\nEpoch 53/100\n12/12 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9529\nEpoch 53: val_loss did not improve from 0.04827\n12/12 [==============================] - 18s 1s/step - loss: 0.1139 - accuracy: 0.9529 - val_loss: 0.1509 - val_accuracy: 0.9479\nEpoch 54/100\n12/12 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9806\nEpoch 54: val_loss did not improve from 0.04827\n12/12 [==============================] - 20s 2s/step - loss: 0.0917 - accuracy: 0.9806 - val_loss: 0.1446 - val_accuracy: 0.9375\nEpoch 55/100\n12/12 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9668\nEpoch 55: val_loss did not improve from 0.04827\n12/12 [==============================] - 18s 2s/step - loss: 0.0955 - accuracy: 0.9668 - val_loss: 0.0891 - val_accuracy: 0.9792\nEpoch 56/100\n12/12 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9834\nEpoch 56: val_loss did not improve from 0.04827\n12/12 [==============================] - 17s 2s/step - loss: 0.0499 - accuracy: 0.9834 - val_loss: 0.1582 - val_accuracy: 0.9583\nEpoch 57/100\n12/12 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9695\nEpoch 57: val_loss improved from 0.04827 to 0.04673, saving model to ./fpseweights1.h5\n12/12 [==============================] - 21s 2s/step - loss: 0.0759 - accuracy: 0.9695 - val_loss: 0.0467 - val_accuracy: 0.9896\nEpoch 58/100\n12/12 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9529\nEpoch 58: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 2s/step - loss: 0.1080 - accuracy: 0.9529 - val_loss: 0.1452 - val_accuracy: 0.9375\nEpoch 59/100\n12/12 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9661\nEpoch 59: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.0796 - accuracy: 0.9661 - val_loss: 0.1341 - val_accuracy: 0.9479\nEpoch 60/100\n12/12 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9529\nEpoch 60: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.0964 - accuracy: 0.9529 - val_loss: 0.1893 - val_accuracy: 0.9375\nEpoch 61/100\n12/12 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9612\nEpoch 61: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.0718 - accuracy: 0.9612 - val_loss: 0.0993 - val_accuracy: 0.9583\nEpoch 62/100\n12/12 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9695\nEpoch 62: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.0691 - accuracy: 0.9695 - val_loss: 0.1506 - val_accuracy: 0.9375\nEpoch 63/100\n12/12 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9557\nEpoch 63: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.1234 - accuracy: 0.9557 - val_loss: 0.1229 - val_accuracy: 0.9479\nEpoch 64/100\n12/12 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9501\nEpoch 64: val_loss did not improve from 0.04673\n12/12 [==============================] - 21s 2s/step - loss: 0.1415 - accuracy: 0.9501 - val_loss: 0.3725 - val_accuracy: 0.8854\nEpoch 65/100\n12/12 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9335\nEpoch 65: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.2132 - accuracy: 0.9335 - val_loss: 0.0831 - val_accuracy: 0.9688\nEpoch 66/100\n12/12 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9446\nEpoch 66: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.1803 - accuracy: 0.9446 - val_loss: 0.0951 - val_accuracy: 0.9688\nEpoch 67/100\n12/12 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9640\nEpoch 67: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 2s/step - loss: 0.1234 - accuracy: 0.9640 - val_loss: 0.2048 - val_accuracy: 0.9271\nEpoch 68/100\n12/12 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9446\nEpoch 68: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.1578 - accuracy: 0.9446 - val_loss: 0.1555 - val_accuracy: 0.9479\nEpoch 69/100\n12/12 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9640\nEpoch 69: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.1060 - accuracy: 0.9640 - val_loss: 0.1213 - val_accuracy: 0.9375\nEpoch 70/100\n12/12 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9778\nEpoch 70: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.0763 - accuracy: 0.9778 - val_loss: 0.1639 - val_accuracy: 0.9271\nEpoch 71/100\n12/12 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9612\nEpoch 71: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.1195 - accuracy: 0.9612 - val_loss: 0.0815 - val_accuracy: 0.9792\nEpoch 72/100\n12/12 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9418\nEpoch 72: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 1s/step - loss: 0.1694 - accuracy: 0.9418 - val_loss: 0.3097 - val_accuracy: 0.8646\nEpoch 73/100\n12/12 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9529\nEpoch 73: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.1535 - accuracy: 0.9529 - val_loss: 0.2342 - val_accuracy: 0.9062\nEpoch 74/100\n12/12 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9723\nEpoch 74: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 1s/step - loss: 0.0957 - accuracy: 0.9723 - val_loss: 0.1155 - val_accuracy: 0.9583\nEpoch 75/100\n12/12 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9806\nEpoch 75: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.0526 - accuracy: 0.9806 - val_loss: 0.1301 - val_accuracy: 0.9375\nEpoch 76/100\n12/12 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9557\nEpoch 76: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.0960 - accuracy: 0.9557 - val_loss: 0.0956 - val_accuracy: 0.9688\nEpoch 77/100\n12/12 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9446\nEpoch 77: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 1s/step - loss: 0.1491 - accuracy: 0.9446 - val_loss: 0.3121 - val_accuracy: 0.8750\nEpoch 78/100\n12/12 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9557\nEpoch 78: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.1278 - accuracy: 0.9557 - val_loss: 0.2018 - val_accuracy: 0.9167\nEpoch 79/100\n12/12 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9557\nEpoch 79: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.1362 - accuracy: 0.9557 - val_loss: 0.1856 - val_accuracy: 0.9167\nEpoch 80/100\n12/12 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9751\nEpoch 80: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 1s/step - loss: 0.0817 - accuracy: 0.9751 - val_loss: 0.0802 - val_accuracy: 0.9688\nEpoch 81/100\n12/12 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9751\nEpoch 81: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 1s/step - loss: 0.0897 - accuracy: 0.9751 - val_loss: 0.0775 - val_accuracy: 0.9583\nEpoch 82/100\n12/12 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9723\nEpoch 82: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 2s/step - loss: 0.0672 - accuracy: 0.9723 - val_loss: 0.0606 - val_accuracy: 0.9688\nEpoch 83/100\n12/12 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9418\nEpoch 83: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.1365 - accuracy: 0.9418 - val_loss: 0.2392 - val_accuracy: 0.9062\nEpoch 84/100\n12/12 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9529\nEpoch 84: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.1423 - accuracy: 0.9529 - val_loss: 0.1493 - val_accuracy: 0.9479\nEpoch 85/100\n12/12 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9501\nEpoch 85: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 2s/step - loss: 0.1149 - accuracy: 0.9501 - val_loss: 0.1036 - val_accuracy: 0.9479\nEpoch 86/100\n12/12 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9751\nEpoch 86: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.0607 - accuracy: 0.9751 - val_loss: 0.1436 - val_accuracy: 0.9583\nEpoch 87/100\n12/12 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9889\nEpoch 87: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 1s/step - loss: 0.0676 - accuracy: 0.9889 - val_loss: 0.0609 - val_accuracy: 0.9792\nEpoch 88/100\n12/12 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9612\nEpoch 88: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.0983 - accuracy: 0.9612 - val_loss: 0.3249 - val_accuracy: 0.9167\nEpoch 89/100\n12/12 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9584\nEpoch 89: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.1020 - accuracy: 0.9584 - val_loss: 0.3189 - val_accuracy: 0.8854\nEpoch 90/100\n12/12 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9668\nEpoch 90: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.1101 - accuracy: 0.9668 - val_loss: 0.2404 - val_accuracy: 0.9062\nEpoch 91/100\n12/12 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9609\nEpoch 91: val_loss did not improve from 0.04673\n12/12 [==============================] - 22s 2s/step - loss: 0.1205 - accuracy: 0.9609 - val_loss: 0.2189 - val_accuracy: 0.9479\nEpoch 92/100\n12/12 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9557\nEpoch 92: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 1s/step - loss: 0.1300 - accuracy: 0.9557 - val_loss: 0.1611 - val_accuracy: 0.9583\nEpoch 93/100\n12/12 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.9474\nEpoch 93: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.1201 - accuracy: 0.9474 - val_loss: 0.1009 - val_accuracy: 0.9479\nEpoch 94/100\n12/12 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9751\nEpoch 94: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 1s/step - loss: 0.0735 - accuracy: 0.9751 - val_loss: 0.2490 - val_accuracy: 0.9062\nEpoch 95/100\n12/12 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9723\nEpoch 95: val_loss did not improve from 0.04673\n12/12 [==============================] - 20s 2s/step - loss: 0.0655 - accuracy: 0.9723 - val_loss: 0.1097 - val_accuracy: 0.9375\nEpoch 96/100\n12/12 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9778\nEpoch 96: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.0663 - accuracy: 0.9778 - val_loss: 0.1302 - val_accuracy: 0.9583\nEpoch 97/100\n12/12 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9778\nEpoch 97: val_loss did not improve from 0.04673\n12/12 [==============================] - 17s 2s/step - loss: 0.0432 - accuracy: 0.9778 - val_loss: 0.1244 - val_accuracy: 0.9688\nEpoch 98/100\n12/12 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9778\nEpoch 98: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 1s/step - loss: 0.0735 - accuracy: 0.9778 - val_loss: 0.0976 - val_accuracy: 0.9688\nEpoch 99/100\n12/12 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9668\nEpoch 99: val_loss did not improve from 0.04673\n12/12 [==============================] - 19s 2s/step - loss: 0.0747 - accuracy: 0.9668 - val_loss: 0.1236 - val_accuracy: 0.9375\nEpoch 100/100\n12/12 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9751\nEpoch 100: val_loss did not improve from 0.04673\n12/12 [==============================] - 18s 2s/step - loss: 0.0900 - accuracy: 0.9751 - val_loss: 0.1268 - val_accuracy: 0.9479\n","output_type":"stream"}]},{"cell_type":"code","source":"MobileNetModel.save('LAAMD1.h5')\nInceptionV3Model.save('LAAIV3D1.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Local MobileNet Model Validation Evaluation","metadata":{}},{"cell_type":"code","source":"# 6. Evaluate the model\nMobileNetEvaluation = MobileNetModel.evaluate(validation_generator)\nprint(\"Validation Accuracy: {:.2f}%\".format(MobileNetEvaluation[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:23:31.206397Z","iopub.execute_input":"2023-10-12T15:23:31.207516Z","iopub.status.idle":"2023-10-12T15:23:34.296148Z","shell.execute_reply.started":"2023-10-12T15:23:31.207468Z","shell.execute_reply":"2023-10-12T15:23:34.295023Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 2s 525ms/step - loss: 0.0419 - accuracy: 0.9898\nValidation Accuracy: 98.98%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Local InceptionV3 Model Validation Evaluation","metadata":{}},{"cell_type":"code","source":"# 6. Evaluate the model\nInceptionV3Evaluation = InceptionV3Model.evaluate(validation_generator)\nprint(\"Validation Accuracy: {:.2f}%\".format(InceptionV3Evaluation[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T16:10:06.588137Z","iopub.execute_input":"2023-10-12T16:10:06.588552Z","iopub.status.idle":"2023-10-12T16:10:10.459663Z","shell.execute_reply.started":"2023-10-12T16:10:06.588520Z","shell.execute_reply":"2023-10-12T16:10:10.458605Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 3s 762ms/step - loss: 0.0950 - accuracy: 0.9796\nValidation Accuracy: 97.96%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Common TestGenerator Declaration Module","metadata":{}},{"cell_type":"code","source":"# Test data directory\ntest_data_dir = '/kaggle/input/cataract-image-dataset/processed_images/test'\ninput_shape = (224, 224)\nbatch_size = 32\n\n# Preprocess the test images\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=input_shape,\n    batch_size=batch_size,\n    class_mode='categorical',  # Set to 'categorical' if you used the updated code\n    shuffle=False\n)\n\n# Load the saved model\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:23:44.614146Z","iopub.execute_input":"2023-10-12T15:23:44.614527Z","iopub.status.idle":"2023-10-12T15:23:44.629131Z","shell.execute_reply.started":"2023-10-12T15:23:44.614492Z","shell.execute_reply":"2023-10-12T15:23:44.627953Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Found 121 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# # Local MobileNet Model Test Evaluation","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the test set\nMobileNetTestEvaluation = MobileNetModel.evaluate_generator(test_generator)\nprint(\"Test Accuracy: {:.2f}%\".format(MobileNetTestEvaluation[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:23:50.642830Z","iopub.execute_input":"2023-10-12T15:23:50.643170Z","iopub.status.idle":"2023-10-12T15:23:55.899763Z","shell.execute_reply.started":"2023-10-12T15:23:50.643141Z","shell.execute_reply":"2023-10-12T15:23:55.898797Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_59/4230226302.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  MobileNetTestEvaluation = MobileNetModel.evaluate_generator(test_generator)\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 95.87%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Local InceptionV3 Model Test Evaluation","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the test set\nInceptionV3TestEvaluation = InceptionV3Model.evaluate_generator(test_generator)\nprint(\"Test Accuracy: {:.2f}%\".format(InceptionV3TestEvaluation[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-12T16:10:20.735939Z","iopub.execute_input":"2023-10-12T16:10:20.736295Z","iopub.status.idle":"2023-10-12T16:10:27.060850Z","shell.execute_reply.started":"2023-10-12T16:10:20.736267Z","shell.execute_reply":"2023-10-12T16:10:27.059699Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_59/1916027015.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  InceptionV3TestEvaluation = InceptionV3Model.evaluate_generator(test_generator)\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 95.04%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Common Classification Report Module","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Load the saved model\n#model = tf.keras.models.load_model('models/final_model.h5')  # Update with the correct path\n\n# Get the true labels for the test set\ntrue_labels = test_generator.classes\n\n# Compute and print the classification report\nclass_names = list(test_generator.class_indices.keys())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Local MobileNet Model Classification Report","metadata":{}},{"cell_type":"code","source":"# Generate predictions for the test set\nMobileNetPredictions = MobileNetModel.predict_generator(test_generator)\nMobileNetPredicted_labels = np.argmax(MobileNetPredictions, axis=1)\nMobileNetReport = classification_report(true_labels, MobileNetPredicted_labels, target_names=class_names)\nprint(MobileNetReport)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, balanced_accuracy_score, average_precision_score, confusion_matrix\n\ndef evaluate_classification(y_true, y_pred, average='macro'):\n    \"\"\"\n    Evaluate the classification performance and calculate micro-average, balanced accuracy, and average precision.\n\n    Parameters:\n        y_true (numpy array or list): True labels.\n        y_pred (numpy array or list): Predicted labels.\n        average (str, optional): The averaging strategy to use for average precision.\n                                 Possible values are 'macro', 'micro', 'weighted', and None.\n                                 Default is 'macro'.\n\n    Returns:\n        report (str): The classification report as a string.\n        balanced_acc (float): The balanced accuracy.\n        avg_precision (float): The average precision.\n        micro_avg_precision (float): The micro-average precision.\n        micro_avg_recall (float): The micro-average recall.\n        micro_avg_f1_score (float): The micro-average F1-score.\n    \"\"\"\n    report = classification_report(y_true, y_pred, output_dict=True, zero_division=1)\n    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n    avg_precision = average_precision_score(y_true, y_pred, average=average)\n\n    # Calculate micro-average precision and recall using confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    tp_sum = np.sum(np.diag(cm))\n    pred_sum = np.sum(cm, axis=0)\n    true_sum = np.sum(cm, axis=1)\n    micro_avg_precision = tp_sum / pred_sum.sum()\n    micro_avg_recall = tp_sum / true_sum.sum()\n    micro_avg_f1_score = 2 * (micro_avg_precision * micro_avg_recall) / (micro_avg_precision + micro_avg_recall)\n\n    return report, balanced_acc, avg_precision, micro_avg_precision, micro_avg_recall, micro_avg_f1_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report, balanced_acc, avg_precision, micro_avg_precision, micro_avg_recall, micro_avg_f1_score = evaluate_classification(true_labels,  MobileNetPredicted_labels)\n\n# Print the classification report and additional metrics\n#print(\"Classification Report:\\n\", report)\nprint(\"Micro-average F1-score:\", micro_avg_f1_score)\nprint(\"Balanced Accuracy:\", balanced_acc)\nprint(\"Average Precision:\", avg_precision)\nprint(\"Micro-average Precision:\", micro_avg_precision)\nprint(\"Micro-average Recall:\", micro_avg_recall)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"import numpy as np\nfrom sklearn.metrics import roc_auc_score, balanced_accuracy_score, average_precision_score, f1_score\n\nnum_bootstrap_samples = 5000\nbootstrap_scores = []\n\nfor _ in range(num_bootstrap_samples):\n    # Generate a random bootstrap sample from the predictions with replacement\n    bootstrap_indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n    bootstrap_sample = MobileNetPredicted_labels[bootstrap_indices]\n\n    # Calculate evaluation metrics for the bootstrap sample\n    bootstrap_auc = roc_auc_score(true_labels[bootstrap_indices], bootstrap_sample)\n    bootstrap_balanced_accuracy = balanced_accuracy_score(true_labels[bootstrap_indices], bootstrap_sample)\n    bootstrap_avg_precision = average_precision_score(true_labels[bootstrap_indices], bootstrap_sample)\n    bootstrap_f1_score = f1_score(true_labels[bootstrap_indices], bootstrap_sample)\n\n    # Store the evaluation metric scores for the bootstrap sample\n    bootstrap_scores.append((bootstrap_auc, bootstrap_balanced_accuracy, bootstrap_avg_precision, bootstrap_f1_score))\n\n# Calculate the mean and standard deviation of evaluation metrics based on the bootstrap samples\nmean_auc, std_auc = np.mean([score[0] for score in bootstrap_scores]), np.std([score[0] for score in bootstrap_scores])\nmean_balanced_accuracy, std_balanced_accuracy = np.mean([score[1] for score in bootstrap_scores]), np.std([score[1] for score in bootstrap_scores])\nmean_avg_precision, std_avg_precision = np.mean([score[2] for score in bootstrap_scores]), np.std([score[2] for score in bootstrap_scores])\nmean_f1_score, std_f1_score = np.mean([score[3] for score in bootstrap_scores]), np.std([score[3] for score in bootstrap_scores])\n\n# Calculate the 95% confidence intervals\nconf_interval_auc = (mean_auc - 1.96 * std_auc, mean_auc + 1.96 * std_auc)\nconf_interval_balanced_accuracy = (mean_balanced_accuracy - 1.96 * std_balanced_accuracy, mean_balanced_accuracy + 1.96 * std_balanced_accuracy)\nconf_interval_avg_precision = (mean_avg_precision - 1.96 * std_avg_precision, mean_avg_precision + 1.96 * std_avg_precision)\nconf_interval_f1_score = (mean_f1_score - 1.96 * std_f1_score, mean_f1_score + 1.96 * std_f1_score)\n\n# Print the results\nprint(\"Original AUC:\", roc_auc_score(true_labels, MobileNetPredicted_labels))\nprint(\"95% Confidence Interval for AUC:\", conf_interval_auc)\n\nprint(\"Original Balanced Accuracy:\", balanced_accuracy_score(true_labels, MobileNetPredicted_labels))\nprint(\"95% Confidence Interval for Balanced Accuracy:\", conf_interval_balanced_accuracy)\n\nprint(\"Original Average Precision:\", average_precision_score(true_labels, MobileNetPredicted_labels))\nprint(\"95% Confidence Interval for Average Precision:\", conf_interval_avg_precision)\n\nprint(\"Original F1-score:\", f1_score(true_labels, MobileNetPredicted_labels))\nprint(\"95% Confidence Interval for F1-score:\", conf_interval_f1_score)\n","metadata":{}},{"cell_type":"markdown","source":"# Local InceptionV3 Model Classification Report","metadata":{}},{"cell_type":"code","source":"# Generate predictions for the test set\nInceptionV3Predictions = InceptionV3Model.predict_generator(test_generator)\nInceptionV3Predicted_labels = np.argmax(InceptionV3Predictions, axis=1)\nInceptionV3Report = classification_report(true_labels, InceptionV3Predicted_labels, target_names=class_names)\nprint(InceptionV3Report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"import numpy as np\nfrom sklearn.metrics import roc_auc_score, balanced_accuracy_score, average_precision_score, f1_score\n\nnum_bootstrap_samples = 5000\nbootstrap_scores = []\n\nfor _ in range(num_bootstrap_samples):\n    # Generate a random bootstrap sample from the predictions with replacement\n    bootstrap_indices = np.random.choice(len(true_labels), len(true_labels), replace=True)\n    bootstrap_sample = InceptionV3Predicted_labels[bootstrap_indices]\n\n    # Calculate evaluation metrics for the bootstrap sample\n    bootstrap_auc = roc_auc_score(true_labels[bootstrap_indices], bootstrap_sample)\n    bootstrap_balanced_accuracy = balanced_accuracy_score(true_labels[bootstrap_indices], bootstrap_sample)\n    bootstrap_avg_precision = average_precision_score(true_labels[bootstrap_indices], bootstrap_sample)\n    bootstrap_f1_score = f1_score(true_labels[bootstrap_indices], bootstrap_sample)\n\n    # Store the evaluation metric scores for the bootstrap sample\n    bootstrap_scores.append((bootstrap_auc, bootstrap_balanced_accuracy, bootstrap_avg_precision, bootstrap_f1_score))\n\n# Calculate the mean and standard deviation of evaluation metrics based on the bootstrap samples\nmean_auc, std_auc = np.mean([score[0] for score in bootstrap_scores]), np.std([score[0] for score in bootstrap_scores])\nmean_balanced_accuracy, std_balanced_accuracy = np.mean([score[1] for score in bootstrap_scores]), np.std([score[1] for score in bootstrap_scores])\nmean_avg_precision, std_avg_precision = np.mean([score[2] for score in bootstrap_scores]), np.std([score[2] for score in bootstrap_scores])\nmean_f1_score, std_f1_score = np.mean([score[3] for score in bootstrap_scores]), np.std([score[3] for score in bootstrap_scores])\n\n# Calculate the 95% confidence intervals\nconf_interval_auc = (mean_auc - 1.96 * std_auc, mean_auc + 1.96 * std_auc)\nconf_interval_balanced_accuracy = (mean_balanced_accuracy - 1.96 * std_balanced_accuracy, mean_balanced_accuracy + 1.96 * std_balanced_accuracy)\nconf_interval_avg_precision = (mean_avg_precision - 1.96 * std_avg_precision, mean_avg_precision + 1.96 * std_avg_precision)\nconf_interval_f1_score = (mean_f1_score - 1.96 * std_f1_score, mean_f1_score + 1.96 * std_f1_score)\n\n# Print the results\nprint(\"Original AUC:\", roc_auc_score(true_labels, InceptionV3Predicted_labels))\nprint(\"95% Confidence Interval for AUC:\", conf_interval_auc)\n\nprint(\"Original Balanced Accuracy:\", balanced_accuracy_score(true_labels, InceptionV3Predicted_labels))\nprint(\"95% Confidence Interval for Balanced Accuracy:\", conf_interval_balanced_accuracy)\n\nprint(\"Original Average Precision:\", average_precision_score(true_labels, InceptionV3Predicted_labels))\nprint(\"95% Confidence Interval for Average Precision:\", conf_interval_avg_precision)\n\nprint(\"Original F1-score:\", f1_score(true_labels, InceptionV3Predicted_labels))\nprint(\"95% Confidence Interval for F1-score:\", conf_interval_f1_score)\n","metadata":{}},{"cell_type":"markdown","source":"# Local MobileNet Model Confusion Matrix","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom mlxtend.plotting import plot_confusion_matrix\n\n\n# Load the saved model\n#model = tf.keras.models.load_model('models/final_model.h5')  # Update with the correct path\n\n# Generate predictions for the test data\n\n\n# Generate the confusion matrix\nMobileNetCM = confusion_matrix(true_labels, MobileNetPredicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(5, 3))\nclass_names = list(test_generator.class_indices.keys())\n#sns.heatmap(MobileNetCM, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplot_confusion_matrix(conf_mat=MobileNetCM, figsize=(5, 3), class_names=['Cataract', 'Normal'], show_normed=True)\nplt.title('LAAMD1 Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig('LAAMD1.eps',dpi=250)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Local Inceptionv3 Model Confusion Matrix","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Load the saved model\n#model = tf.keras.models.load_model('models/final_model.h5')  # Update with the correct path\n\n# Generate predictions for the test data\n\n\n# Generate the confusion matrix\nInceptionV3CM = confusion_matrix(true_labels, InceptionV3Predicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(5, 3))\nclass_names = list(test_generator.class_indices.keys())\n#sns.heatmap(InceptionV3CM, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplot_confusion_matrix(conf_mat=InceptionV3CM, figsize=(5, 3), class_names=['Cataract', 'Normal'], show_normed=True)\nplt.title('LAAIV3D1 Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.savefig('LAAIV3D1.eps',dpi=250)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report, balanced_acc, avg_precision, micro_avg_precision, micro_avg_recall, micro_avg_f1_score = evaluate_classification(true_labels,  InceptionV3Predicted_labels)\n\n# Print the classification report and additional metrics\n#print(\"Classification Report:\\n\", report)\nprint(\"Micro-average F1-score:\", micro_avg_f1_score)\nprint(\"Balanced Accuracy:\", balanced_acc)\nprint(\"Average Precision:\", avg_precision)\nprint(\"Micro-average Precision:\", micro_avg_precision)\nprint(\"Micro-average Recall:\", micro_avg_recall)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\n\nfpr_model1, tpr_model1, thresholds_model1 = roc_curve(true_labels, MobileNetPredicted_labels)\nauc_model1 = roc_auc_score(true_labels, MobileNetPredicted_labels)\n\n# Calculate ROC curve and AUC for Model 2\nfpr_model2, tpr_model2, thresholds_model2 = roc_curve(true_labels, InceptionV3Predicted_labels)\nauc_model2 = roc_auc_score(true_labels, InceptionV3Predicted_labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot ROC curves\nplt.figure(figsize=(8, 6))\nplt.plot(fpr_model1, tpr_model1, label='LocalMobileNetD1 (AUC = {:.2f})'.format(auc_model1))\nplt.plot(fpr_model2, tpr_model2, label='LocalInceptionV3D1 (AUC = {:.2f})'.format(auc_model2))\nplt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve Comparison')\nplt.legend(loc='lower right')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\n# Assuming you have predictions and true labels for both models\n# Replace 'MobileNetPredicted_labels' and 'InceptionV3Predicted_labels' with the predictions of your models\n# Replace 'true_labels' with the true labels of your data\n\n# Calculate precision-recall curve for Model 1\nprecision_model1, recall_model1, thresholds_model1 = precision_recall_curve(true_labels, MobileNetPredicted_labels)\n\n# Calculate precision-recall curve for Model 2\nprecision_model2, recall_model2, thresholds_model2 = precision_recall_curve(true_labels, InceptionV3Predicted_labels)\n\nimport matplotlib.pyplot as plt\n\n# Plot the precision-recall curves for both models\nplt.figure(figsize=(8, 6))\nplt.plot(recall_model1, precision_model1, marker='.', label='LocalMobileNetD1')\nplt.plot(recall_model2, precision_model2, marker='.', label='LocalInceptionV3D1')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve Comparison')\nplt.legend()\n\n# Annotate points with precision-recall values for Model 1\nfor p, r, t in zip(precision_model1, recall_model1, thresholds_model1):\n    plt.annotate(f'LGMobileNet: {t:.2f}\\n{p:.2f}/{r:.2f}', xy=(r, p), xytext=(r + 0.03, p), arrowprops=dict(arrowstyle='->'), fontsize=8)\n\n# Annotate points with precision-recall values for Model 2\nfor p, r, t in zip(precision_model2, recall_model2, thresholds_model2):\n    plt.annotate(f'LGInceptionV3: {t:.2f}\\n{p:.2f}/{r:.2f}', xy=(r, p), xytext=(r - 0.15, p), arrowprops=dict(arrowstyle='->'), fontsize=8)\n\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MobileNetModel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Step 1: Load and preprocess the image data (Replace 'your_image_path' with the image you want to visualize)\n# Step 1: Load and preprocess the image data\ntest_folder = '/kaggle/input/cataract-image-dataset/processed_images/test'\ninput_size = (224, 224)  # Input size of the model, adjust according to your model's input size\n# Step 2: Pick 4 sample images (2 from 'cataract' class and 2 from 'normal' class)\nclass_folders = ['cataract', 'normal']\nsample_images = []\n\nfor class_folder in class_folders:\n    class_path = os.path.join(test_folder, class_folder)\n    images = os.listdir(class_path)\n    sample_images.extend(random.sample(images, 2))\n\ndef preprocess_image(image_path, input_size):\n    img = load_img(image_path, target_size=input_size)\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = tf.keras.applications.vgg16.preprocess_input(img)  # Preprocess based on VGG16 requirements\n    return img\n\n\n# Step 3: Define a function to compute the Grad-CAM visualization\ndef compute_gradcam(model, image):\n    # Get the last convolutional layer and the output layer of the model\n    last_conv_layer = model.get_layer('multiply')\n    output_layer = model.layers[-1]\n\n    # Create a model that maps the input image to the output class predictions and the last convolutional layer\n    grad_model = Model(inputs=model.input, outputs=[last_conv_layer.output, output_layer.output])\n\n    # Compute the gradients of the predicted class with respect to the last convolutional layer\n    with tf.GradientTape() as tape:\n        conv_output, predictions = grad_model(image)\n        loss = predictions[:, 0]  # Assuming binary classification, change this if you have different output classes\n\n    grads = tape.gradient(loss, conv_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # Multiply each channel in the feature map by its corresponding gradient importance\n    conv_output = conv_output[0]\n    heatmap = tf.reduce_sum(tf.multiply(conv_output, pooled_grads), axis=-1)\n    heatmap = np.maximum(heatmap, 0)  # Apply ReLU activation\n    heatmap /= np.max(heatmap)  # Normalize the heatmap values between 0 and 1\n\n    return heatmap\n\n\n# Create a figure with subplots for original images and their Grad-CAM images\nnum_images = len(sample_images)\nfig, axes = plt.subplots(2, num_images, figsize=(4*num_images, 8))\n\n# Generate Grad-CAM for each image and plot the results\nfor i, image_name in enumerate(sample_images):\n    class_folder = 'cataract' if 'cataract' in image_name else 'normal'\n    image_path = os.path.join(test_folder, class_folder, image_name)\n    image = preprocess_image(image_path, input_size)\n    heatmap = compute_gradcam(MobileNetModel, image)\n    heatmap = cv2.resize(heatmap, (input_size[1], input_size[0]))\n    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n\n    # Load the original image\n    original_image = cv2.imread(image_path)\n    original_image = cv2.resize(original_image, (input_size[1], input_size[0]))\n\n    # Overlay the heatmap on the original image\n    alpha = 0.5  # Adjust the alpha value for the heatmap overlay\n    superimposed_img = cv2.addWeighted(original_image, alpha, heatmap, 1 - alpha, 0)\n\n    # Display the original image and Grad-CAM side by side\n    axes[0, i].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n    axes[0, i].set_title('Original Image')\n    axes[0, i].axis('off')\n\n    axes[1, i].imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n    axes[1, i].set_title('Grad-CAM Visualization')\n    axes[1, i].axis('off')\n\nplt.tight_layout()\n#plt.savefig('LGAAM_D1_GradCamVisualization.eps',dpi=300)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the Grad-CAM heatmap:\n\nRegions with warm colors (e.g., red, orange, and yellow) indicate high importance or high activation. \nThese regions are crucial for the model's prediction, and the model relies heavily on the features extracted \nfrom these areas to make its decision.\n\nRegions with cool colors (e.g., blue and green) indicate low importance or low activation. \nThese regions are less relevant to the model's prediction, and the model does not rely much on \nthe features from these areas to make its decision.\n\nIn a binary classification scenario like this, where the model predicts between 'cataract' and 'normal' \nclasses, the heatmap will show which parts of the image the model considers important for classifying \nthe input as 'cataract' (warm regions) and which parts are not as relevant for the 'normal' class (cool regions).","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.applications import MobileNet, InceptionV3\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Path to the dataset\ndataset_dir = 'd:/chaman/cataract_dataset3'\ntrain_dir = os.path.join(dataset_dir, 'train')\ntest_dir = os.path.join(dataset_dir, 'test')\n\n# Image size for the models\nimage_size = (224, 224)\nbatch_size = 32\nnum_classes = 2\nepochs = 10\n\n# Implement the data loading and preparation functions\ndef prepare_data():\n    datagen = ImageDataGenerator(rescale=1.0/255.0,rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,\n    shear_range=0.2,zoom_range=0.2,horizontal_flip=True, validation_split=0.2)\n    train_generator = datagen.flow_from_directory(train_dir, target_size=image_size, batch_size=batch_size,\n                                                  class_mode='categorical', subset='training', shuffle=True)\n    val_generator = datagen.flow_from_directory(train_dir, target_size=image_size, batch_size=batch_size,\n                                                class_mode='categorical', subset='validation', shuffle=False)\n\n    return train_generator, val_generator\n\ndef train_model(model_fn, input_shape, num_classes, train_generator, val_generator):\n    model = model_fn(input_shape, num_classes)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n    return model\n\ndef bagging_ensemble(models, val_generator):\n    # Make predictions for each model\n    predictions = [model.predict(val_generator) for model in models]\n    # Average the predictions of all models\n    return np.mean(predictions, axis=0)\n\ndef stacking_ensemble(models, meta_model, val_generator):\n    # Make predictions for each model\n    predictions = [model.predict(val_generator) for model in models]\n    stacked_predictions = np.hstack(predictions)\n\n    # Use the stacked predictions to train the meta-model\n    meta_model.fit(stacked_predictions, val_generator.classes, epochs=epochs)\n\n    # Make predictions using the meta-model\n    ensemble_predictions = [model.predict(val_generator) for model in models]\n    stacked_ensemble_predictions = np.hstack(ensemble_predictions)\n    meta_predictions = meta_model.predict(stacked_ensemble_predictions)\n\n    return meta_predictions\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Prepare the data\n    train_generator, val_generator = prepare_data()\n\n    # Ensemble size (the number of models in the ensemble)\n    ensemble_size = 5\n\n    # Create and train ensemble models\n    ensemble_models = []\n    for i in range(ensemble_size):\n        # Bootstrap sampling (with replacement) for training data\n        train_generator_sample = train_generator\n        model_fn = create_Local_attention_augmented_mobilenet if i % 2 == 0 else create_Local_Inceptionv3_model\n        model = train_model(model_fn, image_size + (3,), num_classes, train_generator_sample, val_generator)\n        ensemble_models.append(model)\n\n    # Create the meta-model for stacking\n    input_shape = (ensemble_size * num_classes,)\n    meta_model = tf.keras.Sequential([\n        Input(shape=input_shape),\n        Dense(64, activation='relu'),\n        Dense(num_classes, activation='softmax')\n    ])\n    meta_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    # Make predictions using the stacking ensemble method\n    stacking_predictions = stacking_ensemble(ensemble_models, meta_model, val_generator)\n\n    # Threshold predictions for binary classification\n    y_val = val_generator.classes\n    stacking_predictions_binary = (stacking_predictions.argmax(axis=1) > 0.5).astype(int)\n\n    # Evaluate the stacking ensemble performance\n    stacking_accuracy = np.mean(stacking_predictions_binary == y_val)\n    print(f\"Stacking Ensemble Accuracy: {stacking_accuracy}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data using the stacking ensemble method\ntest_stacking_predictions = stacking_ensemble(ensemble_models, meta_model, test_generator)\n\n    # Threshold predictions for binary classification (if necessary)\ntest_stacking_predictions_binary = (test_stacking_predictions.argmax(axis=1) > 0.5).astype(int)\n\n    # Evaluate the stacking ensemble performance on test data\ny_test = test_generator.classes\ntest_stacking_accuracy = np.mean(test_stacking_predictions_binary == y_test)\nprint(f\"Stacking Ensemble Accuracy on Test Data: {test_stacking_accuracy}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the classification report\nclass_names = test_generator.class_indices\nclass_names = [class_name for class_name, index in sorted(class_names.items(), key=lambda x: x[1])]\nreport = classification_report(y_test, test_stacking_predictions_binary, target_names=class_names)\nprint(\"Classification Report:\")\nprint(report)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport bootstrapped.bootstrap as bs\nimport bootstrapped.stats_functions as bs_stats\nfrom sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score\n\n# Assuming you have your true_labels and MobileNetPredicted_labels defined\n\n# Function to calculate AUC for a given sample\ndef calculate_auc(sample):\n    return roc_auc_score(true_labels[sample], MobileNetPredicted_labels[sample])\n\n# Function to calculate balanced accuracy for a given sample (micro-averaged)\ndef calculate_balanced_accuracy(sample):\n    return balanced_accuracy_score(true_labels[sample], MobileNetPredicted_labels[sample], adjusted=True)\n\n# Function to calculate F1-score for a given sample (micro-averaged)\ndef calculate_f1_score(sample):\n    return f1_score(true_labels[sample], MobileNetPredicted_labels[sample], average='micro')\n\n# Number of bootstrap samples\nnum_bootstrap_samples = 5000\n\n# Generate bootstrap indices (bootstrap_samples) for each iteration\nbootstrap_samples = [np.random.choice(len(true_labels), len(true_labels), replace=True) for _ in range(num_bootstrap_samples)]\n\n# Calculate bootstrap AUCs\nbootstrap_aucs = np.array([calculate_auc(sample) for sample in bootstrap_samples])\n\n# Calculate bootstrap balanced accuracies (micro-averaged)\nbootstrap_balanced_accuracies = np.array([calculate_balanced_accuracy(sample) for sample in bootstrap_samples])\n\n# Calculate bootstrap F1-scores (micro-averaged)\nbootstrap_f1_scores = np.array([calculate_f1_score(sample) for sample in bootstrap_samples])\n\n# Calculate bootstrap confidence intervals using bootstrapped library\nauc_ci = bs.bootstrap(bootstrap_aucs, stat_func=bs_stats.mean, alpha=0.05)\nbalanced_accuracy_ci = bs.bootstrap(bootstrap_balanced_accuracies, stat_func=bs_stats.mean, alpha=0.05)\nf1_score_ci = bs.bootstrap(bootstrap_f1_scores, stat_func=bs_stats.mean, alpha=0.05)\n\n# Print the results\nprint(\"Original AUC:\", roc_auc_score(true_labels, MobileNetPredicted_labels))\nprint(\"95% Confidence Interval for AUC:\", auc_ci)\n\nprint(\"Original Balanced Accuracy (Micro-averaged):\", balanced_accuracy_score(true_labels, MobileNetPredicted_labels, adjusted=True))\nprint(\"95% Confidence Interval for Balanced Accuracy (Micro-averaged):\", balanced_accuracy_ci)\n\nprint(\"Original F1-score (Micro-averaged):\", f1_score(true_labels, MobileNetPredicted_labels, average='micro'))\nprint(\"95% Confidence Interval for F1-score (Micro-averaged):\", f1_score_ci)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\nfrom keras import backend as K\nfrom keras.activations import sigmoid\nMobileNetModelWA = create_Local_attention_augmented_mobilenet(input_shape + (3,), num_classes,attention=False)\n\n# 4. Compile the model\nMobileNetModelWA.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InceptionV3ModelWA = create_Local_Inceptionv3_model(input_shape + (3,), num_classes,attention=False)\n\nInceptionV3ModelWA.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=100\n# Create a directory to save the best model weights during training\nos.makedirs('models', exist_ok=True)\nmodel_checkpoint = ModelCheckpoint('models/best_LocalInceptionModel1.h5', save_best_only=True, save_weights_only=True)\n\nInceptionV3historyWA = InceptionV3ModelWA.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[model_checkpoint,cp_callback2]\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Evaluate the model\nInceptionV3WAEvaluation = InceptionV3ModelWA.evaluate(validation_generator)\nprint(\"Validation Accuracy: {:.2f}%\".format(InceptionV3WAEvaluation[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate predictions for the test set\nInceptionV3PredictionsWA = InceptionV3ModelWA.predict_generator(test_generator)\nInceptionV3Predicted_labelsWA = np.argmax(InceptionV3PredictionsWA, axis=1)\nInceptionV3ReportWA = classification_report(true_labels, InceptionV3Predicted_labelsWA, target_names=class_names)\nprint(InceptionV3ReportWA)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Train the model\nepochs = 100\n\n# Create a directory to save the best model weights during training\nos.makedirs('models', exist_ok=True)\nmodel_checkpoint = ModelCheckpoint('models/best_localmobilnetmodel1.h5', save_best_only=True, save_weights_only=True)\n\nhistoryWA = MobileNetModelWA.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[model_checkpoint,cp_callback1]\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nMobileNetTestEvaluationWA = MobileNetModelWA.evaluate_generator(test_generator)\nprint(\"Test Accuracy: {:.2f}%\".format(MobileNetTestEvaluationWA[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}